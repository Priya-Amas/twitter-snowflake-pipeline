# ğŸ¦ Twitter to Snowflake Data Pipeline

This is an end-to-end real-world data pipeline that:

1. Fetches tweets from Twitter API (v2)
2. Saves them as CSV files
3. Uploads the CSVs to Snowflake
4. Orchestrates everything using Apache Airflow

---

## ğŸš€ Technologies Used

- **Python** ğŸ
- **Snowflake** â„ï¸
- **Apache Airflow** ğŸ›«
- **Git & GitHub**
- **Bash (Ubuntu via WSL2)**

---

## ğŸ“ Project Structure

```bash
.
â””â”€â”€ snowflake_twitter_pipeline
    â”œâ”€â”€ airflow/
    â”‚   â”œâ”€â”€ airflow.cfg
    â”‚   â”œâ”€â”€ airflow.db
    â”‚   â”œâ”€â”€ dags/
    â”‚   â”œâ”€â”€ logs/
    â”‚   â””â”€â”€ webserver_config.py
    â”œâ”€â”€ cached_tweets.json
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ sql/
    â”‚   â”œâ”€â”€ tweets_<timestamp>.csv
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ load_to_snowflake.py
    â”‚   â””â”€â”€ twitter_to_csv.py
    â”œâ”€â”€ tests/
    â”‚   â””â”€â”€ test_twitter_to_csv.py
    â””â”€â”€ venv/
```

---

## ğŸ› ï¸ How to Run the Project

### 1. Clone the Repository

```bash
git clone https://github.com/<your-username>/snowflake_twitter_pipeline.git
cd snowflake_twitter_pipeline
```

### 2. Create & Activate Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables

Create a `.env` file in the root folder and add your secrets:

```
TWITTER_BEARER_TOKEN=your_twitter_token
SNOWFLAKE_USER=your_user
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_WAREHOUSE=your_warehouse
SNOWFLAKE_DATABASE=your_database
SNOWFLAKE_SCHEMA=your_schema
SNOWFLAKE_STAGE=your_internal_stage
```

> **Note:** `.env` is excluded from Git using `.gitignore`.

---

## ğŸŒ€ Running Apache Airflow

### Initialize Airflow DB

```bash
airflow db migrate
```

### Start Airflow

```bash
airflow scheduler
airflow webserver
```

Then visit: [http://localhost:8080](http://localhost:8080)

---

## âœ… Airflow DAG Tasks

- `fetch_tweets`: Fetches recent tweets from the Twitter API and saves them as CSVs.
- `load_to_snowflake`: Uploads those CSV files into a Snowflake table using the Python connector.

---

## ğŸ§ª Testing

```bash
pytest tests/
```

Tests are written using `pytest` to validate the tweet-fetching and transformation logic.

---

## ğŸ”’ Security

- All sensitive keys are stored in a `.env` file.
- `.gitignore` ensures no credentials are pushed to GitHub.

---

## ğŸ‘©â€ğŸ’» Author

**Priya A**  
Snowflake Data Engineer

---

## â­ï¸ Give it a Star

If you find this project helpful, feel free to â­ï¸ the repo to support the author!
